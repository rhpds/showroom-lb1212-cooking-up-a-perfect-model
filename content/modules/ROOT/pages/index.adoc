// modules/ROOT/pages/workshop.adoc
= Welcome to the workshop!
:page-nav-title: Workshop Intro
:page-description: Hands‑on lab on customizing LLMs using InstructLab

Thank you for joining this hands‑on lab focused on customizing large language models (LLMs) using https://instructlab.ai[InstructLab]! InstructLab is an open‑source project licensed under Apache 2.0, leveraging the same link:https://arxiv.org/abs/2403.01081[Large‑scale Alignment for chatBots (LAB)] methodology utilized by Red Hat’s enterprise‑grade AI solutions. Today, we’ll explore how to effectively apply InstructLab’s powerful tools—including Retrieval‑Augmented Generation (RAG), alignment tuning, and synthetic data generation (SDG)—to cook up the perfect model!



== What you’ll be learning in today’s workshop

Today, you’ll walk through the full process of adapting a foundation model to better understand and respond to your unique data—no deep ML background required. By the end of the session, you’ll be able to:

* Prepare Markdown and qna.yaml datasets for fine‑tuning
* Generate high‑quality synthetic data using InstructLab’s automated SDG pipeline
* Fine‑tune foundation models such as Mistral & Granite
* Evaluate your model’s responses and validate their alignment with your enterprise data
* Serve and use your customized AI model locally on consumer‑grade hardware

What's your challenge today? You'll be customizing a foundation model to help out 404 Airlines with their customer service. 404 Airlines is a fictional airline that has a lot of customer service inquiries. They want to build a model that can help them answer questions about their policies, flight status, and other customer service inquiries- by integrating their internal data into the model.

image::instructlab-graphic.png[InstructLab graphic, width=600, align="center"]

== Model Customization with InstructLab and Red Hat Enterprise Linux AI

Today, we’ll work with InstructLab, a community‑driven, open‑source tool designed for local experimentation and customization. InstructLab leverages the original LAB methodology (SDG 1.0) to help you build precise, instruction‑following models through a streamlined synthetic data generation and fine‑tuning workflow.

InstructLab highlights:

* Uses the SDG 1.0 pipeline with simple flows for cleaning and aligning data  
* Supports quantized models and *consumer‑grade/laptop hardware* +  
  Fine‑tunes using *QLoRA* or *LoRA* on top of models like Mistral 7B  
* Great for experimentation and learning on BYO setups (CPU/GPU)

In contrast, Red Hat Enterprise Linux AI uses the same core methodology but with SDG 1.5, which introduces agentic flows, production‑grade fine‑tuning on full‑resolution models, and out‑of‑the‑box hardware optimizations for enterprise scale.

This workshop will show you how to build and refine models using InstructLab—so you can later scale or transition those workflows into an enterprise environment if needed.
